
<h1 align="center">üåÄ PromptCT: Prompting Lipschitz-constrained Network for Multiple-in-One Sparse-view CT Reconstruction</h1>

<p align="center">
  <strong>Baoshun Shi, Ke Jiang, Qiusheng Lian, Xinran Yu, Huazhu Fu</strong><br>
  <em>TMI 2025 (Under Review)</em>
</p>


<p align="center">
  <a href="https://github.com/shibaoshun/PromptCT">
    <img src="https://img.shields.io/badge/Code-GitHub-black?logo=github" alt="github">
  </a>
  <a href="https://pytorch.org/">
    <img src="https://img.shields.io/badge/PyTorch-1.10+-ee4c2c?logo=pytorch" alt="pytorch">
  </a>
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="license">
</p>


---

> **Abstract**  
> Despite significant advancements in deep learning-based sparse-view computed tomography (SVCT) reconstruction algorithms, these methods still encounter two primary limitations: (i) It is challenging to explicitly prove that the prior networks of deep unfolding algorithms satisfy Lipschitz constraints due to their empirically designed nature. (ii) The substantial storage costs of training a separate model for each setting in the case of multiple views hinder practical clinical applications. To address these issues, we elaborate an explicitly provable Lipschitz-constrained network, dubbed LipNet, and integrate an explicit prompt module to provide discriminative knowledge of different sparse sampling settings, enabling the treatment of multiple sparse view configurations within a single model. Furthermore, we develop a storage-saving deep unfolding framework for multiple-in-one SVCT reconstruction, termed **PromptCT**, which embeds LipNet as its prior network to ensure the convergence of its corresponding iterative algorithm. In simulated and real data experiments, PromptCT outperforms benchmark reconstruction algorithms in multiple-in-one SVCT reconstruction, achieving higher-quality reconstructions with lower storage costs. On the theoretical side, we explicitly demonstrate that LipNet satisfies boundary property, further proving its Lipschitz continuity and subsequently analyzing the convergence of the proposed iterative algorithms.

---
**Network Architecture:**  
![Network Architecture](https://github.com/shibaoshun/PromptCT/blob/main/fig/fig1.jpg?raw=true)

**Reconstruction Results:**  
![Reconstruction Results](https://github.com/shibaoshun/PromptCT/blob/main/fig/fig2.jpg?raw=true)




## üìö Table of Contents

- [üöÄ Installation](#-installation)
- [üìÇ Dataset Preparation](#-dataset-preparation)
- [üß† Training](#-training)
- [üîç Testing](#-testing)
- [üìà Results](#-results)
- [üìÑ Citation](#-citation)
- [üìú License & Acknowledgement](#-license--acknowledgement)

---

## üöÄ Installation

This project is implemented with **PyTorch 1.10.0** and supports both **CPU** and **GPU (CUDA)** environments.  
For best performance, we recommend running on a GPU-enabled system.

### ‚úÖ Recommended Environment

- Python ‚â• 3.8  
- PyTorch ‚â• 1.10.0  
- CUDA ‚â• 11.3  
- GPU: NVIDIA RTX 3090 / A100 or equivalent  
- OS: Ubuntu 20.04 / Windows 10+

### üîß Installation Steps

### Please make sure your environment meets the following requirements:

```bash
git clone https://github.com/shibaoshun/PromptCT.git
cd PromptCT
pip install -r requirements.txt
```

## üìÇ Dataset Preparation

You can download the **training and testing datasets** from Baidu Drive:


üìÅ **Dataset**

 üîó [https://pan.baidu.com/s/1lQRFUrkaUH7uEDB6iyKq0Q?pwd=2025](https://pan.baidu.com/s/16bQk82x7qzOfViV71hNS9A?pwd=2025)
 
 üîë **Password:** `2025`

After downloading, place the data under:

```
PromptCT/
 ‚îú‚îÄ‚îÄ data/
 ‚îÇ    ‚îú‚îÄ‚îÄ train/
 ‚îÇ    ‚îú‚îÄ‚îÄ val/
 ‚îÇ    ‚îî‚îÄ‚îÄ test/
```

------

## üß† Training

You can train the model using the default configuration with a single command:

```
python main.py --phase tr
```

------

## üîç Testing

### üî∏ Pretrained Models

Download pretrained models from:




üìÅ **Pretrained Checkpoints**

 üîó [https://pan.baidu.com/s/1xbyzy7vOlVyc-vQjKDqcBA?pwd=2025](https://pan.baidu.com/s/1tSWmJAVUyVCjMlBUUtY7Zg?pwd=2025)
 
 üîë **Password:** `2025`

Place them under:

```
PromptCT/
 ‚îú‚îÄ‚îÄ result/
 ‚îÇ    ‚îú‚îÄ‚îÄ sparse/
 ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ ckp/
 ‚îÇ    ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ best.pth
```

### üî∏ Example Testing Command

```
python main.py --phase test
```

> Results and reconstruction outputs will be saved under `./result/`.

------

## üìà Results

PromptCT achieves **superior reconstruction quality** with significantly **lower storage costs**, enabling **multiple sparse-view CT reconstruction in a single model**.

| Method       | PSNR (dB) ‚Üë | SSIM ‚Üë | Storage ‚Üì |
| ------------ | ----------- | ------ | --------- |
| FBP          | 16.17       | 0.5719 | -         |
| LipCT        | 39.37       | 0.9406 | 37.9      |
| MLipCT       | 38.62       | 0.9351 | 9.5       |
| **PromptCT** | 39.49       | 0.9410 | 12.5      |

------

## üìÑ Citation

If you find this work useful, please cite:

```
@ARTICLE{11222836,
  author={Shi, Baoshun and Jiang, Ke and Lian, Qiusheng and Yu, Xinran and Fu, Huazhu},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Prompting Lipschitz-constrained network for multiple-in-one sparse-view CT reconstruction}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  keywords={Image reconstruction;Convergence;Iterative methods;Computed tomography;Reconstruction algorithms;Costs;X-ray imaging;Training;Optimization;Image restoration;Sparse-view computed tomography;deep unfolding network;convergence analysis;prompt learning},
  doi={10.1109/TMI.2025.3627305}}

```

------

## üìú License & Acknowledgement

This project is released under the MIT License.
 We would like to thank all contributors and referenced works for their valuable resources and datasets.

------

<p align="center">‚≠ê If you find this repository useful, please give it a star to support us! ‚≠ê</p> ```

